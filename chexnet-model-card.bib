% Encoding: UTF-8

@misc{PAIR,
  author       = {{PAIR with Google}},
  date         = {2020},
  title        = {{Measuring Fairness}},
  year         = {2020},
  howpublished = {\href{https://pair.withgoogle.com/explorables/measuring-fairness}{Link to publication 2020-06-05}},
  url          = {https://pair.withgoogle.com/explorables/measuring-fairness},
  urldate      = {2020-06-05}
}

@article{Mulligan2019,
  author    = {Deirdre K. Mulligan and Joshua A. Kroll and Nitin Kohli and Richmond Y. Wong},
  title     = {{This Thing Called Fairness: Disciplinary Confusion Realizing a Value in Technology}},
  number    = {CSCW},
  pages     = {1--36},
  url       = {https://arxiv.org/pdf/1909.11869.pdf},
  volume    = {3},
  journal   = {Proceedings of the ACM on Human-Computer Interaction},
  publisher = {ACM New York, NY, USA},
  year      = {2019}
}

@article{Allen2019,
  author    = {James A. Allen},
  title     = {{The Color of Algorithms: An Analysis and Proposed Research Agenda for Deterring Algorithmic Redlining}},
  pages     = {219},
  volume    = {46},
  journal   = {Fordham Urban Law Journal},
  publisher = {HeinOnline},
  year      = {2019}
}

@book{Barocas2019,
  author    = {Solon Barocas and Moritz Hardt and Arvind Narayanan},
  date      = {2019-12-06},
  title     = {{Fairness and Machine Learning}},
  publisher = {fairmlbook.org},
  url       = {https://fairmlbook.org/},
  urldate   = {2020-06-05}
}

@article{Committee1990,
  author  = {{IEEE Standards Committee}},
  date    = {1990},
  title   = {{IEEE Standard Glossary of Software Engineering Terminology 610.12-1990}},
  year    = {1990},
  url     = {https://ieeexplore.ieee.org/document/159342},
  urldate = {2020-08-07}
}

@misc{Ng2019,
  author       = {Andrew Ng},
  date         = {2019-11-06},
  title        = {{The Batch November 6, 2019}},
  year         = {2019},
  howpublished = {\href{https://info.deeplearning.ai/the-batch-deepmind-masters-starcraft-2-ai-attacks-on-amazon-a-career-in-robot-management-banks-embrace-bots-1}{Link to publication 2020-06-13}},
  url          = {https://info.deeplearning.ai/the-batch-deepmind-masters-starcraft-2-ai-attacks-on-amazon-a-career-in-robot-management-banks-embrace-bots-1},
  urldate      = {2020-06-13}
}

@book{Osoba2019,
  author    = {Osoba, Osonde A. and Boudreaux, Benjamin and Saunders, Jessica and Irwin, J. Luke and Mueller, Pam A. and Cherney, Samantha},
  title     = {{Algorithmic Equity: A Framework for Social Applications}},
  publisher = {RAND Corporation},
  year      = {2019}
}

@book{RoyalSociety2017,
  author    = {{The Royal Society}},
  title     = {{Machine learning : the power and promise of computers that learn by example}},
  editor    = {The Royal Society},
  isbn      = {9781782522591},
  publisher = {The Royal Society},
  url       = {https://royalsociety.org/~/media/policy/projects/machine-learning/publications/machine-learning-report.pdf},
  urldate   = {2020-06-28},
  year      = {2017}
}

@misc{Gangadharan2014,
  author       = {Seeta Peña Gangadharan},
  date         = {2014-10-27},
  title        = {{Data and Discrimination Collected Essays}},
  year         = {2014},
  howpublished = {\href{https://www.newamerica.org/oti/policy-papers/data-and-discrimination/}{Link to publication 2020-06-14}},
  url          = {https://www.newamerica.org/oti/policy-papers/data-and-discrimination/},
  urldate      = {2020-06-14}
}

@book{Munro2020,
  author    = {Munro, Robert},
  date      = {2020-12-29},
  title     = {{Human-In-The-Loop Machine Learning}},
  isbn      = {1617296740},
  pagetotal = {325},
  publisher = {MANNING PUBN},
  url       = {https://www.ebook.de/de/product/39016207/robert_munro_human_in_the_loop_machine_learning.html},
  ean       = {9781617296741},
  year      = {2020}
}

@misc{FAT/ML,
  author       = {FAT/ML},
  title        = {{Principles for Accountable Algorithms and a Social Impact Statement for Algorithms}},
  year         = {2020},
  howpublished = {\href{https://www.fatml.org/resources/principles-for-accountable-algorithms}{Link to publication 2020-06-14}},
  url          = {https://www.fatml.org/resources/principles-for-accountable-algorithms},
  urldate      = {2020-06-16}
}

@article{Suresh2019,
  author  = {Suresh, Harini and Guttag, John V.},
  title   = {{A framework for understanding unintended consequences of machine learning}},
  journal = {arXiv preprint arXiv:1901.10002},
  year    = {2019}
}

@misc{Medscape2020,
  author       = {Medscape},
  date         = {2020-05-20},
  title        = {{Medscape Radiologist Compensation Report 2020}},
  year         = {2020},
  howpublished = {\href{https://www.medscape.com/slideshow/2020-compensation-radiologist-6012747}{Link to publication 2020-06-20}},
  url          = {https://www.medscape.com/slideshow/2020-compensation-radiologist-6012747},
  urldate      = {2020-06-20}
}

@misc{Economist2020a,
  author       = {{The Economist}},
  date         = {2020-06-13},
  editor       = {{The Economist}},
  title        = {{Artificial Intelligence and its Limits - Autumn is coming}},
  year         = {2020},
  howpublished = {\href{https://www.economist.com/technology-quarterly/2020/06/11/humans-will-add-to-ais-limitations}{Link to publication 2020-06-20}},
  url          = {https://www.economist.com/technology-quarterly/2020/06/11/humans-will-add-to-ais-limitations},
  urldate      = {2020-06-20}
}

@article{Zech2018,
  author    = {John R. Zech and Marcus A. Badgeley and Manway Liu and Anthony B. Costa and Joseph J. Titano and Eric Karl Oermann},
  title     = {{Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: A cross-sectional study}},
  year      = {2018},
  doi       = {10.1371/journal.pmed.1002683},
  editor    = {Aziz Sheikh},
  number    = {11},
  pages     = {e1002683},
  publisher = {Public Library of Science ({PLoS})},
  url       = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002683#pmed.1002683.s005},
  volume    = {15},
  journal   = {{PLOS} Medicine},
  month     = {nov}
}

@inproceedings{Beede2020,
  author    = {Emma Beede and Elizabeth Baylor and Fred Hersch and Anna Iurchenko and Lauren Wilcox and Paisan Ruamviboonsuk and Laura M. Vardoulakis},
  booktitle = {{Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems}},
  title     = {{A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy}},
  doi       = {10.1145/3313831.3376718},
  publisher = {ACM},
  month     = {apr},
  year      = {2020}
}

@article{Obermeyer2019,
  author    = {Ziad Obermeyer and Brian Powers and Christine Vogeli and Sendhil Mullainathan},
  title     = {{Dissecting racial bias in an algorithm used to manage the health of populations}},
  doi       = {10.1126/science.aax2342},
  number    = {6464},
  pages     = {447--453},
  volume    = {366},
  journal   = {Science},
  month     = {oct},
  publisher = {American Association for the Advancement of Science ({AAAS})},
  year      = {2019}
}

@inproceedings{Caruana2015,
  author    = {Rich Caruana and Yin Lou and Johannes Gehrke and Paul Koch and Marc Sturm and Noemie Elhadad},
  booktitle = {{Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}},
  title     = {{Intelligible Models for HealthCare}},
  doi       = {10.1145/2783258.2788613},
  publisher = {ACM Press},
  year      = {2015}
}

@misc{Economist2020,
  author       = {{The Economist}},
  date         = {2020-06-13},
  editor       = {{The Economist}},
  title        = {{Artificial Intelligence and its Limits - Reality Check}},
  year         = {2020},
  howpublished = {\href{https://www.economist.com/technology-quarterly/2020/06/11/an-understanding-of-ais-limitations-is-starting-to-sink-in}{Link to publication 2020-06-20}},
  url          = {https://www.economist.com/technology-quarterly/2020/06/11/an-understanding-of-ais-limitations-is-starting-to-sink-in},
  urldate      = {2020-06-20}
}

@misc{Schiffer2020,
  author       = {Zoe Schiffer},
  date         = {2020-01-24},
  title        = {{Aurora is finally ready to show the world what it’s been up to}},
  year         = {2020},
  howpublished = {\href{https://www.theverge.com/2020/1/24/21080298/aurora-self-driving-car-announcement-2020-plan-waymo-ford-general-motors}{Link to publication 2020-06-21}},
  subtitle     = {{The secretive self-driving car company unveiled its plans for 2020}},
  url          = {https://www.theverge.com/2020/1/24/21080298/aurora-self-driving-car-announcement-2020-plan-waymo-ford-general-motors},
  urldate      = {2020-06-21}
}

@article{Nagendran2020,
  author    = {Myura Nagendran and Yang Chen and Christopher A. Lovejoy and Anthony C. Gordon and Matthieu Komorowski and Hugh Harvey and Eric J. Topol and John P. A. Ioannidis and Gary S. Collins and Mahiben Maruthappu},
  title     = {{Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies}},
  doi       = {10.1136/bmj.m689},
  pages     = {m689},
  url       = {https://www.bmj.com/content/368/bmj.m689},
  journal   = {BMJ},
  month     = {mar},
  publisher = {BMJ},
  year      = {2020}
}

@misc{Verma2018,
  author       = {Sahil Verma and Julia Rubin},
  title        = {{Fairness definitions explained}},
  doi          = {10.1145/3194770.3194776},
  howpublished = {\href{https://dl.acm.org/doi/10.1145/3194770.3194776}{Link to publicastion}},
  url          = {https://dl.acm.org/doi/10.1145/3194770.3194776},
  urldate      = {2020-08-07},
  year         = {2018}
}

@misc{Chiappa2019,
  author       = {Silvia Chiappa and William Isaac},
  date         = {2019-10-03},
  title        = {{Causal Bayesian Networks: A flexible tool to enable fairer machine learning}},
  year         = {2019},
  howpublished = {\href{https://deepmind.com/blog/article/Causal_Bayesian_Networks}{Link to publication 2020-06-21}},
  url          = {https://deepmind.com/blog/article/Causal_Bayesian_Networks},
  urldate      = {2020-06-21}
}

@book{Hamon2020,
  author    = {Ronan Hamon},
  title     = {{Robustness and explainability of Artificial Intelligence : from technical to policy solutions}},
  isbn      = {9789276146605},
  publisher = {Publications Office of the European Union},
  address   = {Luxembourg},
  year      = {2020}
}

@misc{Harvey,
  author       = {Hugh Harvey},
  date         = {2020-22-04},
  title        = {{Five shockingly simple questions to ask clinical AI vendors before you buy}},
  year         = {2020},
  howpublished = {\href{https://hardianhealth.com/blog/5questions}{Link to publication 2020-06-23}},
  url          = {https://hardianhealth.com/blog/5questions},
  urldate      = {2020-06-23}
}

@inproceedings{Breck2017,
  author    = {Eric Breck and Shanqing Cai and Eric Nielsen and Michael Salib and D. Sculley},
  booktitle = {{Proceedings of IEEE Big Data}},
  title     = {{The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction}},
  year      = {2017}
}

@inproceedings{Sculley2015,
  author    = {Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean-Francois and Dennison, Dan},
  booktitle = {{Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2}},
  title     = {{Hidden Technical Debt in Machine Learning Systems}},
  location  = {Montreal, Canada},
  pages     = {2503–2511},
  publisher = {MIT Press},
  series    = {NIPS’15},
  url       = {http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf},
  urldate   = {2020-08-22},
  address   = {Cambridge, MA, USA},
  numpages  = {9},
  year      = {2015}
}

@inproceedings{Amershi2019,
  author    = {Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N. and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric},
  booktitle = {{Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems}},
  title     = {{Guidelines for Human-AI Interaction}},
  doi       = {10.1145/3290605.3300233},
  isbn      = {9781450359702},
  location  = {Glasgow, Scotland Uk},
  pages     = {1–13},
  publisher = {Association for Computing Machinery},
  series    = {CHI ’19},
  url       = {https://doi.org/10.1145/3290605.3300233},
  address   = {New York, NY, USA},
  keywords  = {design guidelines, human-ai interaction, ai-infused systems},
  numpages  = {13},
  year      = {2019}
}

@article{Challen2019,
  author    = {Robert Challen and Joshua Denny and Martin Pitt and Luke Gompels and Tom Edwards and Krasimira Tsaneva-Atanasova},
  title     = {{Artificial intelligence, bias and clinical safety}},
  doi       = {10.1136/bmjqs-2018-008370},
  number    = {3},
  pages     = {231--237},
  volume    = {28},
  journal   = {{BMJ} Quality {\&} Safety},
  month     = {jan},
  publisher = {{BMJ}},
  year      = {2019}
}

@Misc{Strickland2019,
  author       = {Eliza Strickland},
  date         = {2019-04-02},
  title        = {{How IBM Watson Overpromised and Underdelivered on AI Health Care}},
  year         = {2019},
  howpublished = {\href{https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care\#LinkToAIHealthTable}{Link to publication 2020-06-24}},
  note         = {IEEE Spectrum},
  url          = {https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care#LinkToAIHealthTable},
  urldate      = {2020-06-24},
}

@misc{Harper2017,
  author       = {Matthew Harper},
  date         = {2017-02-17},
  title        = {{MD Anderson Benches IBM Watson In Setback For Artificial Intelligence In Medicine}},
  year         = {2017},
  howpublished = {\href{https://www.forbes.com/sites/matthewherper/2017/02/19/md-anderson-benches-ibm-watson-in-setback-for-artificial-intelligence-in-medicine/}{Link to publication 2020-08-07}},
  note         = {Forbes},
  url          = {https://www.forbes.com/sites/matthewherper/2017/02/19/md-anderson-benches-ibm-watson-in-setback-for-artificial-intelligence-in-medicine/},
  urldate      = {2020-08-07}
}

@misc{TexasAdministration2017,
  author       = {{The University of Texas Administration}},
  date         = {2017-01},
  title        = {{Special Review of Procurement Procedures Related to the M.D. Anderson Cancer Center Oncology Expert Advisor Project}},
  year         = {2017},
  howpublished = {\href{https://www.utsystem.edu/sites/default/files/documents/UT System Administration Special Review of Procurement Procedures Related to UTMDACC Oncology Expert Advisor Project/ut-system-administration-special-review-procurement-procedures-related-utmdacc-oncology-expert-advis.pdf}{Link to publication 2020-06-24}},
  url          = {https://www.utsystem.edu/sites/default/files/documents/UT System Administration Special Review of Procurement Procedures Related to UTMDACC Oncology Expert Advisor Project/ut-system-administration-special-review-procurement-procedures-related-utmdacc-oncology-expert-advis.pdf},
  urldate      = {2020-06-24}
}

@misc{Heaven2020,
  author       = {Will Douglas Heaven},
  date         = {2020-04-27},
  title        = {{Google’s medical AI was super accurate in a lab. Real life was a different story}},
  year         = {2020},
  howpublished = {\href{https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/}{Link to publication 2020-07-12}},
  note         = {MIT Technology Review},
  url          = {https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/},
  urldate      = {2020-07-12}
}

@misc{Bourque2014,
  author       = {Pierre Bourque and Richard E. Fairley},
  date         = {2014},
  title        = {{Guide to the Software Engineering Body of Knowledge, Version 3.0}},
  year         = {2014},
  howpublished = {\href{https://www.computer.org/education/bodies-of-knowledge/software-engineering}{Link to publication 2020-07-20}},
  note         = {IEEE Computer Society},
  url          = {https://www.computer.org/education/bodies-of-knowledge/software-engineering},
  urldate      = {2020-07-20}
}

@article{Haskins2004,
  author    = {Bill Haskins and Jonette Stecklein and Brandon Dick and Gregory Moroney and Randy Lovell and James Dabney},
  title     = {{Error Cost Escalation Through the Project Life Cycle}},
  doi       = {10.1002/j.2334-5837.2004.tb00608.x},
  number    = {1},
  pages     = {1723--1737},
  volume    = {14},
  journal   = {{INCOSE} International Symposium},
  month     = {jun},
  publisher = {Wiley},
  year      = {2004}
}

@misc{Karpathy2017,
  author       = {Andrej Karpathy},
  date         = {2017-11-11},
  title        = {{Software 2.0}},
  year         = {2017},
  howpublished = {\href{https://medium.com/@karpathy/software-2-0-a64152b37c35}{Link to publication 2020-07-17}},
  url          = {https://medium.com/@karpathy/software-2-0-a64152b37c35},
  urldate      = {2020-07-17}
}

@article{Degani1993,
  author    = {Asaf Degani and Earl L. Wiener},
  title     = {{Cockpit Checklists: Concepts, Design, and Use}},
  doi       = {10.1177/001872089303500209},
  number    = {2},
  pages     = {345--359},
  volume    = {35},
  journal   = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
  month     = {jun},
  publisher = {{SAGE} Publications},
  year      = {1993}
}

@article{Hersch2009,
  author    = {Matthew H. Hersch},
  title     = {{Checklist: The Secret Life of Apollo's "Fourth Crewmember"}},
  doi       = {10.1111/j.1467-954x.2009.01814.x},
  number    = {1{\_}suppl},
  pages     = {6--24},
  volume    = {57},
  journal   = {The Sociological Review},
  month     = {may},
  publisher = {{SAGE} Publications},
  year      = {2009}
}

@misc{Hersch2009a,
  author       = {Matthew Hersch},
  date         = {2009-07-19},
  editor       = {{Air and Space Magazine}},
  title        = {{The Fourth Crewemember}},
  year         = {2009},
  howpublished = {\href{https://www.airspacemag.com/space/the-fourth-crewmember-37046329/}{Link to publication 2020-07-22}},
  note         = {Air and Space Magazine},
  url          = {https://www.airspacemag.com/space/the-fourth-crewmember-37046329/},
  urldate      = {2020-07-22}
}

@book{Gawande2011,
  author    = {Gawande, Atul},
  date      = {2011-02-01},
  title     = {{The Checklist Manifesto}},
  isbn      = {0312430000},
  pagetotal = {215},
  publisher = {Macmillan USA},
  url       = {https://www.ebook.de/de/product/10051625/atul_gawande_the_checklist_manifesto.html},
  ean       = {9780312430009},
  year      = {2011}
}

@book{Institute2012,
  author    = {{Canadian Patient Safety Institute}},
  date      = {2012},
  title     = {{Canadian incident analysis framework}},
  isbn      = {9781926541457},
  publisher = {Canadian Patient Safety Institute},
  url       = {https://www.patientsafetyinstitute.ca/en/toolsResources/IncidentAnalysis/Documents/Canadian Incident Analysis Framework.PDF},
  urldate   = {2020-07-22},
  address   = {Edmonton},
  year      = {2012}
}

@misc{Food2019,
  author       = {{Food and Drug Administration}},
  date         = {2019-04-01},
  title        = {{Code of Federal Regulations Title 21}},
  year         = {2019},
  howpublished = {\href{https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfcfr/cfrsearch.cfm?cfrpart=820}{Link to publication 2020-07-22}},
  url          = {https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfcfr/cfrsearch.cfm?cfrpart=820},
  urldate      = {2020-07-22}
}

@article{Minssen2020,
  author    = {Timo Minssen and Sara Gerke and Mateo Aboy and Nicholson Price and Glenn Cohen},
  title     = {{Regulatory responses to medical machine learning}},
  doi       = {10.1093/jlb/lsaa002},
  journal   = {Journal of Law and the Biosciences},
  month     = {apr},
  publisher = {Oxford University Press ({OUP})},
  year      = {2020}
}

@inproceedings{Raji2020,
  author    = {Inioluwa Deborah Raji and Andrew Smart and Rebecca N. White and Margaret Mitchell and Timnit Gebru and Ben Hutchinson and Jamila Smith-Loud and Daniel Theron and Parker Barnes},
  booktitle = {{Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency}},
  title     = {{Closing the AI accountability gap defining an end-to-end framework for Internal algorithmic auditing v1}},
  doi       = {10.1145/3351095.3372873},
  publisher = {{ACM}},
  month     = {jan},
  year      = {2020}
}

@inproceedings{Kulshrestha2017,
  author    = {Juhi Kulshrestha and Motahhare Eslami and Johnnatan Messias and Muhammad Bilal Zafar and Saptarshi Ghosh and Krishna P. Gummadi and Karrie Karahalios},
  booktitle = {{Proceedings of the 2017 {ACM} Conference on Computer Supported Cooperative Work and Social Computing}},
  title     = {{Quantifying Search Bias}},
  doi       = {10.1145/2998181.2998321},
  publisher = {{ACM}},
  month     = {feb},
  year      = {2017}
}

@article{Willemink2020,
  author    = {Martin J. Willemink and Wojciech A. Koszek and Cailin Hardell and Jie Wu and Dominik Fleischmann and Hugh Harvey and Les R. Folio and Ronald M. Summers and Daniel L. Rubin and Matthew P. Lungren},
  title     = {{Preparing Medical Imaging Data for Machine Learning}},
  doi       = {10.1148/radiol.2020192224},
  number    = {1},
  pages     = {4--15},
  volume    = {295},
  journal   = {Radiology},
  month     = {apr},
  publisher = {Radiological Society of North America ({RSNA})},
  year      = {2020}
}

@article{Liu2019,
  author    = {Xiaoxuan Liu and Livia Faes and Aditya U. Kale and Siegfried K. Wagner and Dun Jack Fu and Alice Bruynseels and Thushika Mahendiran and Gabriella Moraes and Mohith Shamdas and Christoph Kern and Joseph R. Ledsam and Martin K. Schmid and Konstantinos Balaskas and Eric J.Topol and Lucas M. Bachmann and Pearse A. Keane and Alastair K. Denniston},
  title     = {{A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis}},
  doi       = {10.1016/s2589-7500(19)30123-2},
  number    = {6},
  pages     = {e271--e297},
  volume    = {1},
  journal   = {The Lancet Digital Health},
  month     = {oct},
  publisher = {Elsevier {BV}},
  year      = {2019}
}

@article{Connolly2020,
  author    = {Randy Connolly},
  title     = {{Why computing belongs within the social sciences}},
  doi       = {10.1145/3383444},
  number    = {8},
  pages     = {54--59},
  volume    = {63},
  journal   = {Communications of the {ACM}},
  month     = {jul},
  publisher = {Association for Computing Machinery ({ACM})},
  year      = {2020}
}

@article{Shiller2010,
  author    = {Robert J. Shiller},
  title     = {{How Should the Financial Crisis Change How We Teach Economics?}},
  doi       = {10.1080/00220485.2010.510409},
  number    = {4},
  pages     = {403--409},
  volume    = {41},
  journal   = {The Journal of Economic Education},
  month     = {sep},
  publisher = {Informa {UK} Limited},
  year      = {2010}
}

@article{Hagendorff2020,
  author    = {Thilo Hagendorff},
  title     = {{The Ethics of AI Ethics: An Evaluation of Guidelines}},
  doi       = {10.1007/s11023-020-09517-8},
  number    = {1},
  pages     = {99--120},
  volume    = {30},
  journal   = {Minds and Machines},
  month     = {feb},
  publisher = {Springer Science and Business Media {LLC}},
  year      = {2020}
}

@misc{JamesGuszcza2018,
  author       = {James Guszcza and Iyad Rahwan and Will Bible and Manuel Cebrian and Vic Katyal},
  date         = {2018-11-28},
  title        = {{Why we need to audit algorithms}},
  year         = {2018},
  howpublished = {\href{https://hbr.org/2018/11/why-we-need-to-audit-algorithms}{Link to publication 2020-07-26}},
  note         = {Harvard Business Review},
  url          = {https://hbr.org/2018/11/why-we-need-to-audit-algorithms},
  urldate      = {2020-07-26}
}

@misc{Health2017,
  author       = {{National Insititutes of Health}},
  date         = {2017-09-27},
  title        = {{NIH Clinical Center provides one of the largest publicly available chest x-ray datasets to scientific community}},
  year         = {2017},
  howpublished = {\href{https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community}{Link to publication 2020-07-27}},
  url          = {https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community},
  urldate      = {2020-07-27}
}

@inproceedings{Wang2017,
  author    = {Xiaosong Wang and Yifan Peng and Le Lu and Zhiyong Lu and Mohammadhadi Bagheri and Ronald M. Summers},
  booktitle = {{2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})}},
  title     = {{ChestX-ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases v5}},
  doi       = {10.1109/cvpr.2017.369},
  publisher = {{IEEE}},
  month     = {jul},
  year      = {2017}
}

@misc{OakdenRayner2019,
  author       = {Luke Oakden-Rayner},
  date         = {2019-02-19},
  title        = {{Half a million x-rays! First impressions of the Stanford and MIT chest x-ray datasets}},
  year         = {2019},
  howpublished = {\href{https://lukeoakdenrayner.wordpress.com/2019/02/25/half-a-million-x-rays-first-impressions-of-the-stanford-and-mit-chest-x-ray-datasets/}{Link to publication 2020-07-27}},
  url          = {https://lukeoakdenrayner.wordpress.com/2019/02/25/half-a-million-x-rays-first-impressions-of-the-stanford-and-mit-chest-x-ray-datasets/},
  urldate      = {2020-07-27}
}

@misc{OakdenRayner2017,
  author       = {Luke Oakden-Rayner},
  date         = {2017-11-18},
  title        = {{Quick thoughts on ChestXray14, performance claims, and clinical tasks}},
  year         = {2017},
  howpublished = {\href{https://lukeoakdenrayner.wordpress.com/2017/11/18/quick-thoughts-on-chestxray14-performance-claims-and-clinical-tasks/}{Link to publication 2020-07-27}},
  url          = {https://lukeoakdenrayner.wordpress.com/2017/11/18/quick-thoughts-on-chestxray14-performance-claims-and-clinical-tasks/},
  urldate      = {2020-07-27}
}

@article{Baltruschat2019,
  author    = {Ivo M. Baltruschat and Hannes Nickisch and Michael Grass and Tobias Knopp and Axel Saalbach},
  title     = {{Comparison of Deep Learning Approaches for Multi-Label Chest X-Ray Classification}},
  doi       = {10.1038/s41598-019-42294-8},
  number    = {1},
  volume    = {9},
  journal   = {Scientific Reports},
  month     = {apr},
  publisher = {Springer Science and Business Media {LLC}},
  year      = {2019}
}

@misc{OakdenRayner2018,
  author       = {Luke Oakden-Rayner},
  date         = {2018-12-17},
  title        = {{Exploring the ChestXray14 dataset: problems}},
  year         = {2018},
  howpublished = {\href{https://lukeoakdenrayner.wordpress.com/2017/12/18/the-chestxray14-dataset-problems/}{Link to publication 2020-07-27}},
  url          = {https://lukeoakdenrayner.wordpress.com/2017/12/18/the-chestxray14-dataset-problems/},
  urldate      = {2020-07-27}
}

@article{Rajpurkar2017,
  author      = {Pranav Rajpurkar and Jeremy Irvin and Kaylie Zhu and Brandon Yang and Hershel Mehta and Tony Duan and Daisy Ding and Aarti Bagul and Curtis Langlotz and Katie Shpanskaya and Matthew P. Lungren and Andrew Y. Ng},
  date        = {2017-11-14},
  title       = {{CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning v3}},
  year        = {2017},
  eprint      = {1711.05225v3},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  abstract    = {We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer convolutional neural network trained on ChestX-ray14, currently the largest publicly available chest X-ray dataset, containing over 100,000 frontal-view X-ray images with 14 diseases. Four practicing academic radiologists annotate a test set, on which we compare the performance of CheXNet to that of radiologists. We find that CheXNet exceeds average radiologist performance on the F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and achieve state of the art results on all 14 diseases.},
  file        = {:http\://arxiv.org/pdf/1711.05225v3:PDF},
  keywords    = {cs.CV, cs.LG, stat.ML}
}

@misc{Medicine2017,
  author       = {{Standford School of Medicine}},
  date         = {2017-11-15},
  title        = {{Algorithm better at diagnosing pneumonia than radiologists}},
  year         = {2017},
  howpublished = {\href{http://med.stanford.edu/news/all-news/2017/11/algorithm-can-diagnose-pneumonia-better-than-radiologists.html}{Link to publication 2020-07-27}},
  url          = {http://med.stanford.edu/news/all-news/2017/11/algorithm-can-diagnose-pneumonia-better-than-radiologists.html},
  urldate      = {2020-07-27}
}

@misc{Radiology2017,
  author       = {{Stanford Radiology}},
  date         = {2017-11-15},
  title        = {{Stanford researchers develop algorithm that accurately diagnoses pneumonia}},
  year         = {2017},
  howpublished = {\href{https://med.stanford.edu/radiology/news/2017/ai-research-diagnoses-pneumonia-better.html}{Link to publication 2020-07-27}},
  url          = {https://med.stanford.edu/radiology/news/2017/ai-research-diagnoses-pneumonia-better.html},
  urldate      = {2020-07-27}
}

@misc{OakdenRayner2018a,
  author       = {Luke Oakden-Rayner},
  date         = {2018-01-24},
  title        = {{CheXNet: an in-depth review}},
  year         = {2018},
  howpublished = {\href{https://lukeoakdenrayner.wordpress.com/2018/01/24/chexnet-an-in-depth-review/}{Link to publication 2020-07-27}},
  url          = {https://lukeoakdenrayner.wordpress.com/2018/01/24/chexnet-an-in-depth-review/},
  urldate      = {2020-07-27}
}

@misc{Gebru2018,
  author       = {Timnit Gebru and Jamie Morgenstern and Briana Vecchione and Jennifer Wortman Vaughan and Hanna Wallach and Hal Daumé and Kate Crawford},
  date         = {2018-03-23},
  title        = {{Datasheets for Datasets v7}},
  year         = {2018},
  eprint       = {1803.09010v7},
  eprintclass  = {cs.DB},
  eprinttype   = {arXiv},
  howpublished = {\href{https://arxiv.org/abs/1803.09010}{Link to publication 2020-08-06}},
  url          = {https://arxiv.org/abs/1803.09010},
  urldate      = {2020-08-08},
  abstract     = {The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.},
  file         = {:http\://arxiv.org/pdf/1803.09010v7:PDF},
  keywords     = {cs.DB, cs.AI, cs.LG}
}

@article{Mitchell2018,
  author       = {Margaret Mitchell and Simone Wu and Andrew Zaldivar and Parker Barnes and Lucy Vasserman and Ben Hutchinson and Elena Spitzer and Inioluwa Deborah Raji and Timnit Gebru},
  date         = {2018-10-05},
  journaltitle = {{FAT* '19: Conference on Fairness, Accountability, and Transparency, January 29--31, 2019, Atlanta, GA, USA}},
  title        = {{Model Cards for Model Reporting v2}},
  year         = {2018},
  doi          = {10.1145/3287560.3287596},
  eprint       = {1810.03993v2},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  abstract     = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related AI technology, increasing transparency into how well AI technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.},
  file         = {:http\://arxiv.org/pdf/1810.03993v2:PDF},
  keywords     = {cs.LG, cs.AI}
}

@misc{Topol2017,
  author       = {Eric Topol},
  date         = {2017-11-15},
  title        = {{The arXiv preprint CheXNet suggest, at best, matched 4 academic radiologists.}},
  year         = {2017},
  howpublished = {\href{https://twitter.com/EricTopol/status/930980060835614720}{Link to publication 2020-07-27}},
  url          = {https://twitter.com/EricTopol/status/930980060835614720},
  urldate      = {2020-07-27}
}

@misc{Microsoft2020,
  author       = {Microsoft},
  date         = {2020-04-01},
  title        = {{What are Azure machine learning pipelines?}},
  year         = {2020},
  howpublished = {\href{https://docs.microsoft.com/en-us/azure/machine-learning/concept-ml-pipelines}{Link to publication 2020-07-28}},
  url          = {https://docs.microsoft.com/en-us/azure/machine-learning/concept-ml-pipelines},
  urldate      = {2020-07-28}
}

@misc{Office2019,
  author       = {{Information Comminissioner's Office}},
  date         = {2019-03-26},
  title        = {{An overview of the auditing framework for artifical intelligence and its core components}},
  year         = {2019},
  howpublished = {\href{https://ico.org.uk/about-the-ico/news-and-events/ai-blog-an-overview-of-the-auditing-framework-for-artificial-intelligence-and-its-core-components/}{Link to publication 2020-07-28}},
  url          = {https://ico.org.uk/about-the-ico/news-and-events/ai-blog-an-overview-of-the-auditing-framework-for-artificial-intelligence-and-its-core-components/},
  urldate      = {2020-07-28}
}

@conference{Cramer2019,
  author    = {H. Cramer and K. Holstein and J. Wortman Vaughan and H. Daumé and M. Dudík and H. Wallach and S. Reddy and J. Garcia-Gathright},
  booktitle = {{ACM FAccT}},
  date      = {2019-01-29},
  title     = {{Challenges of incorporating algorithmic fairness into industry practice}},
  url       = {https://drive.google.com/file/d/1rUQkVS0NzSH3IEqZDsczSxBbhYHbjamN/view},
  urldate   = {2020-07-28},
  year      = {2019}
}

@misc{MerriamWebster,
  author       = {Merriam-Webster},
  title        = {{Transparent}},
  year         = {2020},
  howpublished = {\href{https://www.merriam-webster.com/dictionary/transparent}{Link to publication 2020-07-28}},
  url          = {https://www.merriam-webster.com/dictionary/transparent},
  urldate      = {2020-07-28}
}

@article{Reyes2020,
  author    = {Mauricio Reyes and Raphael Meier and S{\'{e}}rgio Pereira and Carlos A. Silva and Fried-Michael Dahlweid and Hendrik von Tengg-Kobligk and Ronald M. Summers and Roland Wiest},
  title     = {{On the Interpretability of Artificial Intelligence in Radiology: Challenges and Opportunities}},
  doi       = {10.1148/ryai.2020190043},
  number    = {3},
  pages     = {e190043},
  volume    = {2},
  journal   = {Radiology: Artificial Intelligence},
  month     = {may},
  publisher = {Radiological Society of North America ({RSNA})},
  year      = {2020}
}

@misc{Anderegg2020,
  author       = {Fabio Anderegg},
  date         = {2020},
  title        = {{Web-demo on interpretability of machine intelligence in medial image computing}},
  year         = {2020},
  howpublished = {\href{http://imimic-workshop.com/demo.html}{Link to publication 2020-07-28}},
  url          = {http://imimic-workshop.com/demo.html},
  urldate      = {2020-07-28}
}

@misc{Eggers2019,
  author       = {William D. Eggers and Amrita Datar and Kevin Coltin},
  date         = {2019},
  title        = {{Government jobs of the future}},
  year         = {2019},
  howpublished = {\href{https://www2.deloitte.com/content/dam/insights/us/articles/4767_FoW-in-govt/DI_Algorithm-auditor.pdf}{Link to publication 2020-07-28}},
  note         = {Deloittle Center for Government Insights},
  url          = {https://www2.deloitte.com/content/dam/insights/us/articles/4767_FoW-in-govt/DI_Algorithm-auditor.pdf},
  urldate      = {2020-07-28}
}

@misc{Google,
  author       = {Google},
  title        = {{Google Cloud Model Cards}},
  year         = {2020},
  howpublished = {\href{https://modelcards.withgoogle.com/about}{Link to publication 2020-07-31}},
  url          = {https://modelcards.withgoogle.com/about},
  urldate      = {2020-07-31}
}

@misc{ThePartnership,
  author       = {{The Partnership on AI}},
  title        = {{ABOUT ML}},
  year         = {2020},
  howpublished = {\href{https://www.partnershiponai.org/about-ml/}{Link to publication 2020-07-31}},
  note         = {The Partnership on AI},
  url          = {https://www.partnershiponai.org/about-ml/},
  urldate      = {2020-07-31}
}

@misc{Partneship2020,
  author       = {{The Partnership on AI}},
  date         = {2020},
  title        = {{Annotation and Benchmarking on Understanding and Transparency of Machine learning Lifecycles (ABOUT ML) chapter 2}},
  year         = {2020},
  howpublished = {\href{https://www.partnershiponai.org/wp-content/uploads/2019/07/ABOUT-ML-v0-Draft-Chapter-2.pdf}{Link to publication 2020-08-01}},
  url          = {https://www.partnershiponai.org/wp-content/uploads/2019/07/ABOUT-ML-v0-Draft-Chapter-2.pdf},
  urldate      = {2020-08-01}
}

@inproceedings{Buolamwini2018,
  author    = {Buolamwini, Joy and Gebru, Timnit},
  booktitle = {{Conference on fairness, accountability and transparency}},
  title     = {{Gender shades: Intersectional accuracy disparities in commercial gender classification}},
  pages     = {77--91},
  year      = {2018}
}

@article{Chan2020,
  author    = {Stephanie Chan and Vidhatha Reddy and Bridget Myers and Quinn Thibodeaux and Nicholas Brownstone and Wilson Liao},
  title     = {{Machine Learning in Dermatology: Current Applications, Opportunities, and Limitations}},
  doi       = {10.1007/s13555-020-00372-0},
  number    = {3},
  pages     = {365--386},
  volume    = {10},
  journal   = {Dermatology and Therapy},
  month     = {apr},
  publisher = {Springer Science and Business Media {LLC}},
  year      = {2020}
}

@misc{Jilani2020,
  author       = {Abdul Khader Jilani},
  date         = {2020-03-31},
  title        = {{Identifying Leakage in Computer Vision on Medical Images}},
  year         = {2020},
  howpublished = {\href{https://www.datarobot.com/blog/identifying-leakage-in-computer-vision-on-medical-images/}{Link to publication 2020-08-02}},
  url          = {https://www.datarobot.com/blog/identifying-leakage-in-computer-vision-on-medical-images/},
  urldate      = {2020-08-02}
}

@book{Groopman2007,
  author    = {Jeremo Groopman},
  date      = {2007},
  title     = {{How Doctors Think}},
  year      = {2007},
  chapter   = {1},
  isbn      = {0-618-61003-0},
  pages     = {40},
  publisher = {Mariner Books}
}

@misc{HealthClinicalCenter2017,
  author       = {{National Institutes of Health Clinical Center}},
  date         = {2017-09-01},
  editor       = {Ronald Summers},
  title        = {{ChestX-ray8}},
  year         = {2017},
  howpublished = {\href{https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345}{Link to publication 2020-08-05}},
  url          = {https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345},
  urldate      = {2020-08-02}
}

@misc{HealthClinicalCenter,
  author       = {{National Institutes of Health Clinical Center}},
  date         = {2017-06-26},
  title        = {{Legal, Ethical, and Safety Issues}},
  year         = {2017},
  howpublished = {\href{https://clinicalcenter.nih.gov/participate/patientinfo/legal1.html}{Link to publication 2020-08-05}},
  url          = {https://clinicalcenter.nih.gov/participate/patientinfo/legal1.html},
  urldate      = {2020-08-05}
}

@misc{Ste2019,
  author       = {Andrew Ste},
  date         = {2019-08},
  title        = {{How to Become More Marketable as a Data Scientist}},
  year         = {2019},
  howpublished = {\href{https://www.kdnuggets.com/2019/08/marketable-data-scientist.html}{Link to publication 2020-08-05}},
  url          = {https://www.kdnuggets.com/2019/08/marketable-data-scientist.html},
  urldate      = {2020-08-05}
}

@article{Sendak2020,
  author    = {Mark P. Sendak and Michael Gao and Nathan Brajer and Suresh Balu},
  title     = {{Presenting machine learning model information to clinical end users with model facts labels}},
  year      = {2020},
  doi       = {10.1038/s41746-020-0253-3},
  number    = {1},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://www.nature.com/articles/s41746-020-0253-3},
  urldate   = {2020-08-23},
  volume    = {3},
  journal   = {npj Digital Medicine},
  month     = {mar}
}

@article{IEC2006,
  author  = {{International Eletrotechnical Commission}},
  title   = {{62304: 2006 Medical device software--software life cycle processes}},
  url     = {https://www.iso.org/standard/38421.html},
  journal = {International Electrotechnical Commission, Geneva},
  year    = {2006}
}

@article{Goldstein2016,
  author    = {Benjamin A. Goldstein and Nrupen A. Bhavsar and Matthew Phelan and Michael J. Pencina},
  title     = {{Controlling for Informed Presence Bias Due to the Number of Health Encounters in an Electronic Health Record}},
  doi       = {10.1093/aje/kww112},
  number    = {11},
  pages     = {847--855},
  url       = {https://pubmed.ncbi.nlm.nih.gov/27852603/},
  volume    = {184},
  journal   = {American Journal of Epidemiology},
  month     = {nov},
  publisher = {Oxford University Press ({OUP})},
  year      = {2016}
}

@article{Phelan2017,
  author    = {Phelan, Matthew and Bhavsar, Nrupen and Goldstein, Benjamin A.},
  title     = {{Illustrating Informed Presence Bias in Electronic Health Records Data: How Patient Interactions with a Health System Can Impact Inference}},
  doi       = {10.5334/egems.243},
  number    = {1},
  pages     = {22},
  volume    = {5},
  journal   = {{eGEMs} (Generating Evidence {\&} Methods to improve patient outcomes)},
  month     = {dec},
  publisher = {Ubiquity Press, Ltd.},
  year      = {2017}
}

@article{Martensson2020,
  author    = {Gustav M{\aa}rtensson and Daniel Ferreira and Tobias Granberg and Lena Cavallin and Ketil Oppedal and Alessandro Padovani and Irena Rektorova and Laura Bonanni and Matteo Pardini and Milica G Kramberger and John-Paul Taylor and Jakub Hort and J{\'{o}}n Sn{\ae}dal and Jaime Kulisevsky and Frederic Blanc and Angelo Antonini and Patrizia Mecocci and Bruno Vellas and Magda Tsolaki and Iwona K{\l}oszewska and Hilkka Soininen and Simon Lovestone and Andrew Simmons and Dag Aarsland and Eric Westman},
  title     = {{The reliability of a deep learning model in clinical out-of-distribution {MRI} data: a multicohort study}},
  doi       = {10.1016/j.media.2020.101714},
  pages     = {101714},
  journal   = {Medical Image Analysis},
  month     = {may},
  publisher = {Elsevier {BV}},
  year      = {2020}
}

@article{Pooch2019,
  author      = {Eduardo H. P. Pooch and Pedro L. Ballester and Rodrigo C. Barros},
  date        = {2019-09-03},
  title       = {{Can we trust deep learning models diagnosis? The impact of domain shift in chest radiograph classification}},
  year        = {2019},
  eprint      = {1909.01940v2},
  eprintclass = {eess.IV},
  eprinttype  = {arXiv},
  abstract    = {While deep learning models become more widespread, their ability to handle unseen data and generalize for any scenario is yet to be challenged. In medical imaging, there is a high heterogeneity of distributions among images based on the equipment that generates them and their parametrization. This heterogeneity triggers a common issue in machine learning called domain shift, which represents the difference between the training data distribution and the distribution of where a model is employed. A high domain shift tends to implicate in a poor generalization performance from the models. In this work, we evaluate the extent of domain shift on four of the largest datasets of chest radiographs. We show how training and testing with different datasets (e.g., training in ChestX-ray14 and testing in CheXpert) drastically affects model performance, posing a big question over the reliability of deep learning models trained on public datasets. We also show that models trained on CheXpert and MIMIC-CXR generalize better to other datasets.},
  file        = {:http\://arxiv.org/pdf/1909.01940v2:PDF},
  keywords    = {eess.IV, cs.AI, cs.CV, cs.LG, stat.ML}
}

@article{Rajpurkar2018,
  author    = {Pranav Rajpurkar and Jeremy Irvin and Robyn L. Ball and Kaylie Zhu and Brandon Yang and Hershel Mehta and Tony Duan and Daisy Ding and Aarti Bagul and Curtis P. Langlotz and Bhavik N. Patel and Kristen W. Yeom and Katie Shpanskaya and Francis G. Blankenberg and Jayne Seekins and Timothy J. Amrhein and David A. Mong and Safwan S. Halabi and Evan J. Zucker and Andrew Y. Ng and Matthew P. Lungren},
  title     = {{Deep learning for chest radiograph diagnosis: A retrospective comparison of the {CheXNeXt} algorithm to practicing radiologists}},
  doi       = {10.1371/journal.pmed.1002686},
  editor    = {Aziz Sheikh},
  number    = {11},
  pages     = {e1002686},
  volume    = {15},
  journal   = {{PLOS} Medicine},
  month     = {nov},
  publisher = {Public Library of Science ({PLoS})},
  year      = {2018}
}

@article{Sun2018,
  author      = {Youcheng Sun and Xiaowei Huang and Daniel Kroening and James Sharp and Matthew Hill and Rob Ashmore},
  date        = {2018-03-10},
  title       = {{Testing Deep Neural Networks}},
  year        = {2018},
  eprint      = {1803.04792v4},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  abstract    = {Deep neural networks (DNNs) have a wide range of applications, and software employing them must be thoroughly tested, especially in safety-critical domains. However, traditional software test coverage metrics cannot be applied directly to DNNs. In this paper, inspired by the MC/DC coverage criterion, we propose a family of four novel test criteria that are tailored to structural features of DNNs and their semantics. We validate the criteria by demonstrating that the generated test inputs guided via our proposed coverage criteria are able to capture undesired behaviours in a DNN. Test cases are generated using a symbolic approach and a gradient-based heuristic search. By comparing them with existing methods, we show that our criteria achieve a balance between their ability to find bugs (proxied using adversarial examples) and the computational cost of test case generation. Our experiments are conducted on state-of-the-art DNNs obtained using popular open source datasets, including MNIST, CIFAR-10 and ImageNet.},
  file        = {:http\://arxiv.org/pdf/1803.04792v4:PDF},
  keywords    = {cs.LG, cs.CV, cs.SE}
}

@inproceedings{Amershi2019a,
  author       = {Amershi, Saleema and Begel, Andrew and Bird, Christian and DeLine, Robert and Gall, Harald and Kamar, Ece and Nagappan, Nachiappan and Nushi, Besmira and Zimmermann, Thomas},
  booktitle    = {{2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)}},
  title        = {{Software engineering for machine learning: A case study}},
  organization = {IEEE},
  pages        = {291--300},
  year         = {2019}
}

@article{Cai2019,
  author    = {Carrie J. Cai and Samantha Winter and David Steiner and Lauren Wilcox and Michael Terry},
  title     = {{"Hello AI": Uncovering the Onboarding Needs of Medical Practitioners for Human-AI Collaborative Decision-Making}},
  year      = {2019},
  doi       = {10.1145/3359206},
  number    = {{CSCW}},
  pages     = {1--24},
  publisher = {Association for Computing Machinery ({ACM})},
  volume    = {3},
  journal   = {Proceedings of the {ACM} on Human-Computer Interaction},
  month     = {nov}
}

@article{Larrazabal2020,
  author    = {Agostina J. Larrazabal and Nicol{\'{a}}s Nieto and Victoria Peterson and Diego H. Milone and Enzo Ferrante},
  title     = {{Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis}},
  year      = {2020},
  doi       = {10.1073/pnas.1919012117},
  number    = {23},
  pages     = {12592--12594},
  publisher = {Proceedings of the National Academy of Sciences},
  volume    = {117},
  journal   = {Proceedings of the National Academy of Sciences},
  month     = {may}
}

@misc{Economist2020b,
  author       = {{The Economist}},
  date         = {2020-06-11},
  title        = {{Driverless cars show the limits of today’s AI}},
  year         = {2020},
  howpublished = {\href{https://www.economist.com/technology-quarterly/2020/06/11/driverless-cars-show-the-limits-of-todays-ai}{Link to publication 2020-08-21}},
  url          = {https://www.economist.com/technology-quarterly/2020/06/11/driverless-cars-show-the-limits-of-todays-ai},
  urldate      = {2020-08-21}
}

@inproceedings{Bottou2015,
  author    = {Léon Bottou},
  booktitle = {{International Conference on Machine Learning}},
  date      = {2015},
  title     = {{Two big challenges in machine learning}},
  url       = {https://icml.cc/2015/invited/LeonBottouICML2015.pdf},
  urldate   = {2020-08-22},
  year      = {2015}
}

@article{Health2019,
  author    = {The Lancet Digital Health},
  title     = {{There is no such thing as race in health-care algorithms}},
  year      = {2019},
  doi       = {10.1016/s2589-7500(19)30201-8},
  number    = {8},
  pages     = {e375},
  publisher = {Elsevier {BV}},
  volume    = {1},
  journal   = {The Lancet Digital Health},
  month     = {dec}
}

@misc{Ledford2019,
  author       = {Heidi Ledford},
  date         = {2019-10-24},
  editor       = {Nature},
  title        = {{Millions of black people affected by racial bias in health-care algorithms}},
  year         = {2019},
  howpublished = {\href{https://www.nature.com/articles/d41586-019-03228-6}{Link to publication 2020-08-22}},
  url          = {https://www.nature.com/articles/d41586-019-03228-6},
  urldate      = {2020-08-22}
}

@article{Sendak2019,
  author      = {Mark Sendak and Madeleine Elish and Michael Gao and Joseph Futoma and William Ratliff and Marshall Nichols and Armando Bedoya and Suresh Balu and Cara O'Brien},
  date        = {2019-11-19},
  title       = {{"The Human Body is a Black Box": Supporting Clinical Decision-Making with Deep Learning}},
  year        = {2019},
  eprint      = {1911.08089v2},
  eprintclass = {cs.CY},
  eprinttype  = {arXiv},
  url         = {https://arxiv.org/abs/1911.08089},
  abstract    = {Machine learning technologies are increasingly developed for use in healthcare. While research communities have focused on creating state-of-the-art models, there has been less focus on real world implementation and the associated challenges to accuracy, fairness, accountability, and transparency that come from actual, situated use. Serious questions remain under examined regarding how to ethically build models, interpret and explain model output, recognize and account for biases, and minimize disruptions to professional expertise and work cultures. We address this gap in the literature and provide a detailed case study covering the development, implementation, and evaluation of Sepsis Watch, a machine learning-driven tool that assists hospital clinicians in the early diagnosis and treatment of sepsis. We, the team that developed and evaluated the tool, discuss our conceptualization of the tool not as a model deployed in the world but instead as a socio-technical system requiring integration into existing social and professional contexts. Rather than focusing on model interpretability to ensure a fair and accountable machine learning, we point toward four key values and practices that should be considered when developing machine learning to support clinical decision-making: rigorously define the problem in context, build relationships with stakeholders, respect professional discretion, and create ongoing feedback loops with stakeholders. Our work has significant implications for future research regarding mechanisms of institutional accountability and considerations for designing machine learning systems. Our work underscores the limits of model interpretability as a solution to ensure transparency, accuracy, and accountability in practice. Instead, our work demonstrates other means and goals to achieve FATML values in design and in practice.},
  file        = {:http\://arxiv.org/pdf/1911.08089v2:PDF},
  keywords    = {cs.CY, cs.AI, cs.HC, cs.LG}
}

@article{Arnold2018,
  author        = {{Arnold}, Matthew and {Bellamy}, Rachel K.~E. and {Hind}, Michael and {Houde}, Stephanie and {Mehta}, Sameep and {Mojsilovic}, Aleksandra and {Nair}, Ravi and {Natesan Ramamurthy}, Karthikeyan and {Reimer}, Darrell and {Olteanu}, Alexandra and {Piorkowski}, David and {Tsay}, Jason and {Varshney}, Kush R.},
  title         = {{FactSheets: Increasing Trust in AI Services through Supplier's Declarations of Conformity}},
  year          = {2018},
  eid           = {arXiv:1808.07261},
  eprint        = {1808.07261},
  pages         = {arXiv:1808.07261},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2018arXiv180807261A},
  archiveprefix = {arXiv},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Computers and Society, Computer Science - Artificial Intelligence},
  month         = aug,
  primaryclass  = {cs.CY}
}

@Misc{Partnership2020,
  author       = {{The Partnership on AI}},
  date         = {2020},
  title        = {{ABOUT ML (Annotation and Benchmarking on Understanding and Transparency of Machine learning Lifecycles)}},
  year         = {2020},
  howpublished = {\href{https://www.partnershiponai.org/about-ml-get-involved/}{Link to publication 2020-08-22}},
  url          = {https://www.partnershiponai.org/about-ml-get-involved/},
  urldate      = {2020-08-23},
}

@misc{Mojsilovic2018,
  author       = {Aleksandra Mojsilovic},
  date         = {2018-08-22},
  editor       = {IBM Research Blog},
  title        = {{Factsheets for AI Services}},
  year         = {2018},
  howpublished = {\href{https://www.ibm.com/blogs/research/2018/08/factsheets-ai/}{Link to publication 2020-08-22}},
  url          = {https://www.ibm.com/blogs/research/2018/08/factsheets-ai/},
  urldate      = {2020-08-23}
}

@misc{CONSORT2020,
  author       = {CONSORT},
  date         = {2020},
  title        = {{CONSORT – CONsolidated Standards Of Reporting Trials}},
  year         = {2020},
  howpublished = {\href{http://www.consort-statement.org/about-consort}{Link to publication 2020-08-22}},
  url          = {http://www.consort-statement.org/about-consort},
  urldate      = {2020-08-23}
}

@misc{TRIPOD2020,
  author       = {TRIPOD},
  date         = {2020},
  title        = {{TRIPOD (Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis)}},
  year         = {2020},
  howpublished = {\href{https://www.tripod-statement.org/}{Link to publication 2020-08-22}},
  url          = {https://www.tripod-statement.org/},
  urldate      = {2020-08-23}
}

@article{Wolff2019,
  author    = {Robert F. Wolff and Karel G.M. Moons and Richard D. Riley and Penny F. Whiting and Marie Westwood and Gary S. Collins and Johannes B. Reitsma and Jos Kleijnen and Sue Mallett and},
  title     = {PROBAST: A Tool to Assess the Risk of Bias and Applicability of Prediction Model Studies},
  year      = {2019},
  doi       = {10.7326/m18-1376},
  number    = {1},
  pages     = {51},
  publisher = {American College of Physicians},
  volume    = {170},
  journal   = {Annals of Internal Medicine},
  month     = {jan}
}

@article{Vollmer2018,
  author      = {Sebastian Vollmer and Bilal A. Mateen and Gergo Bohner and Franz J Király and Rayid Ghani and Pall Jonsson and Sarah Cumbers and Adrian Jonas and Katherine S. L. McAllister and Puja Myles and David Granger and Mark Birse and Richard Branson and Karel GM Moons and Gary S Collins and John P. A. Ioannidis and Chris Holmes and Harry Hemingway},
  date        = {2018-12-21},
  title       = {{Machine learning and AI research for Patient Benefit: 20 Critical Questions on Transparency, Replicability, Ethics and Effectiveness}},
  year        = {2018},
  eprint      = {1812.10404v1},
  eprintclass = {cs.CY},
  eprinttype  = {arXiv},
  abstract    = {Machine learning (ML), artificial intelligence (AI) and other modern statistical methods are providing new opportunities to operationalize previously untapped and rapidly growing sources of data for patient benefit. Whilst there is a lot of promising research currently being undertaken, the literature as a whole lacks: transparency; clear reporting to facilitate replicability; exploration for potential ethical concerns; and, clear demonstrations of effectiveness. There are many reasons for why these issues exist, but one of the most important that we provide a preliminary solution for here is the current lack of ML/AI- specific best practice guidance. Although there is no consensus on what best practice looks in this field, we believe that interdisciplinary groups pursuing research and impact projects in the ML/AI for health domain would benefit from answering a series of questions based on the important issues that exist when undertaking work of this nature. Here we present 20 questions that span the entire project life cycle, from inception, data analysis, and model evaluation, to implementation, as a means to facilitate project planning and post-hoc (structured) independent evaluation. By beginning to answer these questions in different settings, we can start to understand what constitutes a good answer, and we expect that the resulting discussion will be central to developing an international consensus framework for transparent, replicable, ethical and effective research in artificial intelligence (AI-TREE) for health.},
  file        = {:http\://arxiv.org/pdf/1812.10404v1:PDF},
  keywords    = {cs.CY, cs.LG, stat.AP, stat.ML, 68T01}
}

@article{Mongan2020,
  author    = {John Mongan and Linda Moy and Charles E. Kahn},
  title     = {{Checklist for Artificial Intelligence in Medical Imaging (CLAIM): A Guide for Authors and Reviewers}},
  year      = {2020},
  doi       = {10.1148/ryai.2020200029},
  number    = {2},
  pages     = {e200029},
  publisher = {Radiological Society of North America ({RSNA})},
  volume    = {2},
  journal   = {Radiology: Artificial Intelligence},
  month     = {mar}
}

@article{Bluemke2020,
  author    = {David A. Bluemke and Linda Moy and Miriam A. Bredella and Birgit B. Ertl-Wagner and Kathryn J. Fowler and Vicky J. Goh and Elkan F. Halpern and Christopher P. Hess and Mark L. Schiebler and Clifford R. Weiss},
  title     = {{Assessing Radiology Research on Artificial Intelligence: A Brief Guide for Authors, Reviewers, and Readers{\textemdash}From the Radiology Editorial Board}},
  year      = {2020},
  doi       = {10.1148/radiol.2019192515},
  number    = {3},
  pages     = {487--489},
  publisher = {Radiological Society of North America ({RSNA})},
  volume    = {294},
  journal   = {Radiology},
  month     = {mar}
}

@article{Fraser2015,
  author    = {Fraser, Kathleen C. and Meltzer, Jed A. and Rudzicz, Frank},
  title     = {{Linguistic Features Identify Alzheimer’s Disease in Narrative Speech}},
  year      = {2015},
  doi       = {10.3233/JAD-150520},
  editor    = {Garrard, PeterEditor},
  issn      = {1387-2877},
  number    = {2},
  pages     = {407--422},
  publisher = {IOS Press},
  volume    = {49},
  journal   = {Journal of Alzheimer’s Disease},
  month     = {Oct}
}

@misc{Gershgorn2018,
  author       = {Dave Gershgorn},
  date         = {2018-09-06},
  title        = {{If AI is going to be the world’s doctor, it needs better textbooks}},
  year         = {2018},
  howpublished = {\href{https://qz.com/1367177/if-ai-is-going-to-be-the-worlds-doctor-it-needs-better-textbooks/}{Link to publictation 2020-08-24}},
  url          = {https://qz.com/1367177/if-ai-is-going-to-be-the-worlds-doctor-it-needs-better-textbooks/},
  urldate      = {2020-08-24}
}

@article{Irvin2019,
  author        = {{Irvin}, Jeremy and {Rajpurkar}, Pranav and {Ko}, Michael and {Yu}, Yifan and {Ciurea-Ilcus}, Silviana and {Chute}, Chris and {Marklund}, Henrik and {Haghgoo}, Behzad and {Ball}, Robyn and {Shpanskaya}, Katie and {Seekins}, Jayne and {Mong}, David A. and {Halabi}, Safwan S. and {Sandberg}, Jesse K. and {Jones}, Ricky and {Larson}, David B. and {Langlotz}, Curtis P. and {Patel}, Bhavik N. and {Lungren}, Matthew P. and {Ng}, Andrew Y.},
  title         = {{CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison}},
  year          = {2019},
  eid           = {arXiv:1901.07031},
  eprint        = {1901.07031},
  pages         = {arXiv:1901.07031},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2019arXiv190107031I},
  archiveprefix = {arXiv},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
  month         = jan,
  primaryclass  = {cs.CV}
}

@misc{CONSORT2010,
  author       = {CONSORT},
  date         = {2010},
  title        = {{CONSORT 2010 flow diagram}},
  year         = {2010},
  howpublished = {\href{http://www.consort-statement.org/Media/Default/Downloads/CONSORT%202010%20Flow%20Diagram.pdf}{Link to publication 2020-08-24}},
  url          = {http://www.consort-statement.org/Media/Default/Downloads/CONSORT 2010 Flow Diagram.pdf},
  urldate      = {2020-08-26}
}

@book{Bates2000,
  author    = {Bates, Jefferson},
  date      = {2000},
  title     = {{Writing with precision : how to write so that you cannot possibly be misunderstood}},
  year      = {2000},
  chapter   = {8},
  isbn      = {0140288538},
  pages     = {80},
  publisher = {Penguin Books},
  address   = {New York}
}

@misc{GPAIR2017,
  author       = {{Google People + AI Research (PAIR)}},
  date         = {2017},
  title        = {{Facets - know your data}},
  year         = {2017},
  howpublished = {\href{https://pair-code.github.io/facets/}{Link to publicaion 2020-08-31}},
  url          = {https://pair-code.github.io/facets/},
  urldate      = {2020-08-31}
}

@misc{AdrienTreuille2019,
  author       = {Adrien Treuille, Amanda Kelly and Teixeira, Thiago},
  date         = {2019},
  title        = {{Streamlit}},
  year         = {2019},
  howpublished = {\href{https://www.streamlit.io/}{Link to publication 2020-08-31}},
  url          = {https://www.streamlit.io/},
  urldate      = {2020-08-31}
}

@article{Holland2018,
  author        = {{Holland}, Sarah and {Hosny}, Ahmed and {Newman}, Sarah and {Joseph}, Joshua and {Chmielinski}, Kasia},
  title         = {{The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards}},
  year          = {2018},
  eid           = {arXiv:1805.03677},
  eprint        = {1805.03677},
  pages         = {arXiv:1805.03677},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2018arXiv180503677H},
  archiveprefix = {arXiv},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Databases, Computer Science - Computers and Society},
  month         = may,
  primaryclass  = {cs.DB}
}

@article{Kumar2019,
  author        = {{Shankar Siva Kumar}, Ram and {Brien}, David O and {Albert}, Kendra and {Vilj{\"o}en}, Salom{\'e} and {Snover}, Jeffrey},
  title         = {{Failure Modes in Machine Learning Systems}},
  year          = {2019},
  eid           = {arXiv:1911.11034},
  eprint        = {1911.11034},
  pages         = {arXiv:1911.11034},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2019arXiv191111034S},
  archiveprefix = {arXiv},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning, Computer Science - Cryptography and Security, Statistics - Machine Learning},
  month         = nov,
  primaryclass  = {cs.LG}
}

@article{Maguolo2020,
  author        = {{Maguolo}, Gianluca and {Nanni}, Loris},
  title         = {{A Critic Evaluation of Methods for COVID-19 Automatic Detection from X-Ray Images}},
  year          = {2020},
  eid           = {arXiv:2004.12823},
  eprint        = {2004.12823},
  pages         = {arXiv:2004.12823},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2020arXiv200412823M},
  archiveprefix = {arXiv},
  journal       = {arXiv e-prints},
  keywords      = {Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
  month         = apr,
  primaryclass  = {eess.IV}
}

@article{Times1958,
  author       = {{The New York Times}},
  date         = {1958-07-13},
  journaltitle = {{The New York Times}},
  title        = {{Electronic `Brain' Teaches Itself}},
  year         = {1958},
  issue        = {July 13, 1958},
  pages        = {Section E, 9}
}

@misc{AllynBobby2020,
  author       = {Allyn Bobby},
  date         = {2020-06-10},
  title        = {{Amazon Halts Police Use Of Its Facial Recognition Technology}},
  year         = {2020},
  eprint       = {NPR},
  howpublished = {\href{https://www.npr.org/2020/06/10/874418013/amazon-halts-police-use-of-its-facial-recognition-technology}{Link to publication 2020-09-04}},
  note         = {NPR},
  url          = {https://www.npr.org/2020/06/10/874418013/amazon-halts-police-use-of-its-facial-recognition-technology},
  urldate      = {2020-09-04}
}

@misc{ValentinoDeVries2020,
  author       = {Jennifer Valentino-DeVries},
  date         = {2020-06-12},
  title        = {{How the Police Use Facial Recognition, and Where It Falls Short}},
  year         = {2020},
  eprint       = {The New York Times},
  howpublished = {\href{https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html}{Link to publication 2020-09-04}},
  url          = {https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html},
  urldate      = {2020-09-04}
}

@article{Yao2019,
  author        = {{Yao}, Li and {Prosky}, Jordan and {Covington}, Ben and {Lyman}, Kevin},
  title         = {{A Strong Baseline for Domain Adaptation and Generalization in Medical Imaging}},
  year          = {2019},
  eid           = {arXiv:1904.01638},
  eprint        = {1904.01638},
  pages         = {arXiv:1904.01638},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2019arXiv190401638Y},
  archiveprefix = {arXiv},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Electrical Engineering and Systems Science - Image and Video Processing, Statistics - Machine Learning},
  month         = apr,
  primaryclass  = {cs.CV}
}

@article{Bender2018,
  author    = {Emily M. Bender and Batya Friedman},
  title     = {{Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science}},
  year      = {2018},
  doi       = {10.1162/tacl_a_00041},
  pages     = {587--604},
  publisher = {{MIT} Press - Journals},
  volume    = {6},
  journal   = {Transactions of the Association for Computational Linguistics},
  month     = {dec}
}

@article{Liu2020,
  author    = {Xiaoxuan Liu and and Samantha Cruz Rivera and David Moher and Melanie J. Calvert and Alastair K. Denniston},
  title     = {{Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the {CONSORT}-AI extension}},
  year      = {2020},
  doi       = {10.1038/s41591-020-1034-x},
  number    = {9},
  pages     = {1364--1374},
  publisher = {Springer Science and Business Media {LLC}},
  volume    = {26},
  journal   = {Nature Medicine},
  month     = {sep}
}

@article{Miller2019,
  author    = {Tim Miller},
  title     = {{Explanation in artificial intelligence: Insights from the social sciences}},
  year      = {2019},
  doi       = {10.1016/j.artint.2018.07.007},
  pages     = {1--38},
  publisher = {Elsevier {BV}},
  volume    = {267},
  journal   = {Artificial Intelligence},
  month     = {feb}
}

@book{Molnar2020,
  author    = {Molnar, Christoph},
  date      = {2020-02-28},
  title     = {{Interpretable Machine Learning}},
  year      = {2020},
  isbn      = {0244768528},
  pagetotal = {320},
  publisher = {Lulu.com},
  url       = {https://www.ebook.de/de/product/39178906/christoph_molnar_interpretable_machine_learning.html},
  ean       = {9780244768522}
}

@book{Thampi2021,
  author    = {Ajay Thampi},
  date      = {2021},
  title     = {{Interpretable AI - Building Explainable Machine Learning Systems}},
  year      = {2021},
  isbn      = {9781617297649},
  publisher = {Manning Publications}
}

@article{DoshiVelez2017,
  author      = {Finale Doshi-Velez and Been Kim},
  date        = {2017-02-28},
  title       = {{Towards A Rigorous Science of Interpretable Machine Learning}},
  year        = {2017},
  eprint      = {1702.08608v2},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  abstract    = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
  file        = {:http\://arxiv.org/pdf/1702.08608v2:PDF},
  keywords    = {stat.ML, cs.AI, cs.LG}
}

@article{Ribeiro2016,
  author      = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  date        = {2016-02-16},
  title       = {{"Why Should I Trust You?": Explaining the Predictions of Any Classifier}},
  year        = {2016},
  eprint      = {1602.04938v3},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  abstract    = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  file        = {:http\://arxiv.org/pdf/1602.04938v3:PDF},
  keywords    = {cs.LG, cs.AI, stat.ML}
}

@article{Lipton2016,
  author      = {Zachary C. Lipton},
  date        = {2016-06-10},
  title       = {{The Mythos of Model Interpretability}},
  year        = {2016},
  eprint      = {1606.03490v3},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  abstract    = {Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but interpretable. And yet the task of interpretation appears underspecified. Papers provide diverse and sometimes non-overlapping motivations for interpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim interpretability axiomatically, absent further explanation. In this paper, we seek to refine the discourse on interpretability. First, we examine the motivations underlying interest in interpretability, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},
  file        = {:http\://arxiv.org/pdf/1606.03490v3:PDF},
  keywords    = {cs.LG, cs.AI, cs.CV, cs.NE, stat.ML}
}

@misc{Google2020,
  author = {Google},
  date   = {2020},
  title  = {{AI Explanations Whitepaper}},
  year   = {2020},
  note   = {\href{https://storage.googleapis.com/cloud-ai-whitepapers/AI%20Explainability%20Whitepaper.pdf}{Link to publication 2020-09-26}},
  url    = {https://storage.googleapis.com/cloud-ai-whitepapers/AI Explainability Whitepaper.pdf}
}

@article{Phillips2020,
  author    = {P. Jonathon Phillips and Carina A. Hahn and Peter C. Fontana and David A. Broniatowski and Mark A. Przybocki},
  title     = {{Four Principles of Explainable Artificial Intelligence}},
  year      = {2020},
  doi       = {10.6028/nist.ir.8312-draft},
  publisher = {National Institute of Standards and Technology ({NIST})},
  month     = {aug}
}

@article{Lundberg2019,
  author      = {Scott M. Lundberg and Gabriel Erion and Hugh Chen and Alex DeGrave and Jordan M. Prutkin and Bala Nair and Ronit Katz and Jonathan Himmelfarb and Nisha Bansal and Su-In Lee},
  date        = {2019-05-11},
  title       = {{Explainable AI for Trees: From Local Explanations to Global Understanding}},
  year        = {2019},
  eprint      = {1905.04610v1},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  abstract    = {Tree-based machine learning models such as random forests, decision trees, and gradient boosted trees are the most popular non-linear predictive models used in practice today, yet comparatively little attention has been paid to explaining their predictions. Here we significantly improve the interpretability of tree-based models through three main contributions: 1) The first polynomial time algorithm to compute optimal explanations based on game theory. 2) A new type of explanation that directly measures local feature interaction effects. 3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to i) identify high magnitude but low frequency non-linear mortality risk factors in the general US population, ii) highlight distinct population sub-groups with shared risk characteristics, iii) identify non-linear interaction effects among risk factors for chronic kidney disease, and iv) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model's performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.},
  file        = {:http\://arxiv.org/pdf/1905.04610v1:PDF},
  keywords    = {cs.LG, cs.AI, stat.ML}
}

@article{Guidotti2018,
  author      = {Riccardo Guidotti and Anna Monreale and Salvatore Ruggieri and Franco Turini and Dino Pedreschi and Fosca Giannotti},
  date        = {2018-02-06},
  title       = {{A Survey Of Methods For Explaining Black Box Models}},
  year        = {2018},
  eprint      = {1802.01933v3},
  eprintclass = {cs.CY},
  eprinttype  = {arXiv},
  abstract    = {In the last years many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness sometimes at the cost of scarifying accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, delineating explicitly or implicitly its own definition of interpretability and explanation. The aim of this paper is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
  file        = {:http\://arxiv.org/pdf/1802.01933v3:PDF},
  keywords    = {cs.CY, cs.AI, cs.LG}
}

@article{Sayres2019,
  author    = {Rory Sayres and Ankur Taly and Ehsan Rahimy and Katy Blumer and David Coz and Naama Hammel and Jonathan Krause and Arunachalam Narayanaswamy and Zahra Rastegar and Derek Wu and Shawn Xu and Scott Barb and Anthony Joseph and Michael Shumski and Jesse Smith and Arjun B. Sood and Greg S. Corrado and Lily Peng and Dale R. Webster},
  title     = {{Using a Deep Learning Algorithm and Integrated Gradients Explanation to Assist Grading for Diabetic Retinopathy}},
  year      = {2019},
  doi       = {10.1016/j.ophtha.2018.11.016},
  number    = {4},
  pages     = {552--564},
  publisher = {Elsevier {BV}},
  volume    = {126},
  journal   = {Ophthalmology},
  month     = {apr}
}

@article{Rudin2019,
  author    = {Cynthia Rudin},
  title     = {{Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead}},
  year      = {2019},
  doi       = {10.1038/s42256-019-0048-x},
  number    = {5},
  pages     = {206--215},
  publisher = {Springer Science and Business Media {LLC}},
  volume    = {1},
  journal   = {Nature Machine Intelligence},
  month     = {may}
}

@misc{Gunning2017,
  author       = {David Gunning},
  date         = {2017-11},
  title        = {{DARPA Explainable Artificial Intelligence Program Update}},
  year         = {2017},
  howpublished = {\href{https://www.darpa.mil/attachments/XAIProgramUpdate.pdf}{Link to publication 2020-09-27}},
  url          = {https://www.darpa.mil/attachments/XAIProgramUpdate.pdf}
}

@article{Letham2015,
  author       = {Benjamin Letham and Cynthia Rudin and Tyler H. McCormick and David Madigan},
  date         = {2015-11-05},
  journaltitle = {{Annals of Applied Statistics 2015, Vol. 9, No. 3, 1350-1371}},
  title        = {{Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model}},
  year         = {2015},
  doi          = {10.1214/15-AOAS848},
  eprint       = {1511.01644v1},
  eprintclass  = {stat.AP},
  eprinttype   = {arXiv},
  file         = {:http\://arxiv.org/pdf/1511.01644v1:PDF},
  keywords     = {stat.AP, cs.LG, stat.ML}
}

@article{Angelino2017,
  author    = {Angelino, Elaine and Larus-Stone, Nicholas and Alabi, Daniel and Seltzer, Margo and Rudin, Cynthia},
  date      = {2017-01},
  title     = {{Learning certifiably optimal rule lists for categorical data}},
  year      = {2017},
  number    = {1},
  pages     = {8753--8830},
  publisher = {JMLR. org},
  volume    = {18},
  journal   = {The Journal of Machine Learning Research}
}

@article{Chen2018,
  author       = {Chaofan Chen and Oscar Li and Chaofan Tao and Alina Jade Barnett and Jonathan Su and Cynthia Rudin},
  date         = {2018-06-27},
  journaltitle = {{Advances in Neural Information Processing Systems 32 (NeurIPS 2019)}},
  title        = {{This Looks Like That: Deep Learning for Interpretable Image Recognition}},
  year         = {2018},
  eprint       = {1806.10574v5},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  abstract     = {When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture -- prototypical part network (ProtoPNet), that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training without any annotations for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the Stanford Cars dataset. Our experiments show that ProtoPNet can achieve comparable accuracy with its analogous non-interpretable counterpart, and when several ProtoPNets are combined into a larger network, it can achieve an accuracy that is on par with some of the best-performing deep models. Moreover, ProtoPNet provides a level of interpretability that is absent in other interpretable deep models.},
  file         = {:http\://arxiv.org/pdf/1806.10574v5:PDF},
  keywords     = {cs.LG, cs.AI, cs.CV, stat.ML}
}

@article{Li2017,
  author      = {Oscar Li and Hao Liu and Chaofan Chen and Cynthia Rudin},
  date        = {2017-10-13},
  title       = {{Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions}},
  year        = {2017},
  eprint      = {1710.04806v2},
  eprintclass = {cs.AI},
  eprinttype  = {arXiv},
  abstract    = {Deep neural networks are widely used for classification. These deep models often suffer from a lack of interpretability -- they are particularly difficult to understand because of their non-linear nature. As a result, neural networks are often treated as "black box" models, and in the past, have been trained purely to optimize the accuracy of predictions. In this work, we create a novel network architecture for deep learning that naturally explains its own reasoning for each prediction. This architecture contains an autoencoder and a special prototype layer, where each unit of that layer stores a weight vector that resembles an encoded training input. The encoder of the autoencoder allows us to do comparisons within the latent space, while the decoder allows us to visualize the learned prototypes. The training objective has four terms: an accuracy term, a term that encourages every prototype to be similar to at least one encoded input, a term that encourages every encoded input to be close to at least one prototype, and a term that encourages faithful reconstruction by the autoencoder. The distances computed in the prototype layer are used as part of the classification process. Since the prototypes are learned during training, the learned network naturally comes with explanations for each prediction, and the explanations are loyal to what the network actually computes.},
  file        = {:http\://arxiv.org/pdf/1710.04806v2:PDF},
  keywords    = {cs.AI, cs.LG, stat.ML}
}

@book{Watzlawick1993,
  author    = {Watzlawick, Paul},
  date      = {1993-07-01},
  title     = {{Situation is Hopeless, But Not Serious}},
  year      = {1993},
  isbn      = {0393310213},
  pagetotal = {128},
  publisher = {Norton and Company},
  url       = {https://www.ebook.de/de/product/3238409/paul_watzlawick_situation_is_hopeless_but_not_serious.html},
  ean       = {9780393310214}
}

@article{Brundage2020,
  author      = {Miles Brundage and Shahar Avin and Jasmine Wang and Haydn Belfield and Gretchen Krueger and Gillian Hadfield and Heidy Khlaaf and Jingying Yang and Helen Toner and Ruth Fong and Tegan Maharaj and Pang Wei Koh and Sara Hooker and Jade Leung and Andrew Trask and Emma Bluemke and Jonathan Lebensold and Cullen O'Keefe and Mark Koren and Théo Ryffel and JB Rubinovitz and Tamay Besiroglu and Federica Carugati and Jack Clark and Peter Eckersley and Sarah de Haas and Maritza Johnson and Ben Laurie and Alex Ingerman and Igor Krawczuk and Amanda Askell and Rosario Cammarota and Andrew Lohn and David Krueger and Charlotte Stix and Peter Henderson and Logan Graham and Carina Prunkl and Bianca Martin and Elizabeth Seger and Noa Zilberman and Se{\'a}n {\'O} h{\'E}igeartaigh and Frens Kroeger and Girish Sastry and Rebecca Kagan and Adrian Weller and Brian Tse and Elizabeth Barnes and Allan Dafoe and Paul Scharre and Ariel Herbert-Voss and Martijn Rasser and Shagun Sodhani and Carrick Flynn and Thomas Krendl Gilbert and Lisa Dyer and Saif Khan and Yoshua Bengio and Markus Anderljung},
  date        = {2020-04-15},
  title       = {{Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims}},
  year        = {2020},
  eprint      = {2004.07213v2},
  eprintclass = {cs.CY},
  eprinttype  = {arXiv},
  abstract    = {With the recent wave of progress in artificial intelligence (AI) has come a growing awareness of the large-scale impacts of AI systems, and recognition that existing regulations and norms in industry and academia are insufficient to ensure responsible AI development. In order for AI developers to earn trust from system users, customers, civil society, governments, and other stakeholders that they are building AI responsibly, they will need to make verifiable claims to which they can be held accountable. Those outside of a given organization also need effective means of scrutinizing such claims. This report suggests various steps that different stakeholders can take to improve the verifiability of claims made about AI systems and their associated development processes, with a focus on providing evidence about the safety, security, fairness, and privacy protection of AI systems. We analyze ten mechanisms for this purpose--spanning institutions, software, and hardware--and make recommendations aimed at implementing, exploring, or improving those mechanisms.},
  file        = {:http\://arxiv.org/pdf/2004.07213v2:PDF},
  keywords    = {cs.CY}
}

@misc{Economist2020c,
  author       = {{The Economist}},
  date         = {2020-06-21},
  title        = {{For AI, data are harder to come by than you think}},
  year         = {2020},
  howpublished = {\href{https://www.economist.com/technology-quarterly/2020/06/11/for-ai-data-are-harder-to-come-by-than-you-think}{Link to publication 2020-08-21}},
  url          = {https://www.economist.com/technology-quarterly/2020/06/11/for-ai-data-are-harder-to-come-by-than-you-think},
  urldate      = {2020-08-21}
}

@Article{Fitzpatrick1988,
  author    = {T. B. Fitzpatrick},
  title     = {{The validity and practicality of sun-reactive skin types I through VI}},
  year      = {1988},
  doi       = {10.1001/archderm.124.6.869},
  number    = {6},
  pages     = {869--871},
  publisher = {American Medical Association ({AMA})},
  volume    = {124},
  journal   = {Archives of Dermatology},
  month     = {jun},
}

@Article{Dalkey1963,
  author    = {Norman Dalkey and Olaf Helmer},
  title     = {{An Experimental Application of the DELPHI Method to the Use of Experts}},
  year      = {1963},
  doi       = {10.1287/mnsc.9.3.458},
  number    = {3},
  pages     = {458--467},
  publisher = {Institute for Operations Research and the Management Sciences ({INFORMS})},
  volume    = {9},
  journal   = {Management Science},
  month     = {apr},
}

@Article{Selvaraju2019,
  author    = {Ramprasaath R. Selvaraju and Michael Cogswell and Abhishek Das and Ramakrishna Vedantam and Devi Parikh and Dhruv Batra},
  title     = {{Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization}},
  year      = {2019},
  doi       = {10.1007/s11263-019-01228-7},
  number    = {2},
  pages     = {336--359},
  publisher = {Springer Science and Business Media {LLC}},
  volume    = {128},
  journal   = {International Journal of Computer Vision},
  month     = {oct},
}

@Comment{jabref-meta: databaseType:biblatex;}
